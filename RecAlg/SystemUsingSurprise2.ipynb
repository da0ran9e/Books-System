{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ded6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data preparation & visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ignore printing warnings for general readability\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pip install scikit-surprise\n",
    "# Importing libraries for model building & evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
    "from surprise import accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1c63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "def loaddata(filename):\n",
    "    df = pd.read_csv(f'{filename}.csv',sep=';',error_bad_lines=False,warn_bad_lines=False,encoding='latin-1')\n",
    "    return df\n",
    "\n",
    "book   = loaddata(\"./dataset/BX-Books\")\n",
    "user   = loaddata(\"./dataset/BX-Users\")\n",
    "rating = loaddata(\"./dataset/BX-Book-Ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "863e1e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>277427</td>\n",
       "      <td>006092988X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060930535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060932139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>277427</td>\n",
       "      <td>0060934417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147440</th>\n",
       "      <td>275970</td>\n",
       "      <td>1400031354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147441</th>\n",
       "      <td>275970</td>\n",
       "      <td>1400031362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147470</th>\n",
       "      <td>275970</td>\n",
       "      <td>1558744606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147517</th>\n",
       "      <td>275970</td>\n",
       "      <td>1573229725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147584</th>\n",
       "      <td>275970</td>\n",
       "      <td>1853260010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81431 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID        ISBN  Book-Rating\n",
       "1456      277427  002542730X           10\n",
       "1468      277427  006092988X            0\n",
       "1469      277427  0060930535            0\n",
       "1470      277427  0060932139            0\n",
       "1471      277427  0060934417            0\n",
       "...          ...         ...          ...\n",
       "1147440   275970  1400031354            0\n",
       "1147441   275970  1400031362            0\n",
       "1147470   275970  1558744606            0\n",
       "1147517   275970  1573229725            0\n",
       "1147584   275970  1853260010            0\n",
       "\n",
       "[81431 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_users = rating['User-ID'].value_counts().reset_index().\\\n",
    "               rename({'Index':'User-ID','User-ID':'Rating'}, axis=1)\n",
    "rating_books = rating['ISBN'].value_counts().reset_index().\\\n",
    "               rename({'Index':'ISBN','ISBN':'Rating'}, axis=1)\n",
    "# In order to avoid rating bias & for making good recommendations, limit the dataset to only those\n",
    "# users that have made at least 250 ratings & books that have received at least 50 ratings\n",
    "\n",
    "rating = rating[rating['User-ID'].isin(rating_users[rating_users['Rating']>=250]['index'])]\n",
    "rating = rating[rating['ISBN'].isin(rating_books[rating_books['Rating']>=50]['index'])]\n",
    "\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc1c4fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3363</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>6</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12538</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13552</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80889</th>\n",
       "      <td>234828</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>8</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80890</th>\n",
       "      <td>236283</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80891</th>\n",
       "      <td>249628</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80892</th>\n",
       "      <td>261829</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>0</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80893</th>\n",
       "      <td>264321</td>\n",
       "      <td>0345333926</td>\n",
       "      <td>8</td>\n",
       "      <td>Ringworld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80894 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       User-ID        ISBN  Book-Rating  \\\n",
       "0       277427  002542730X           10   \n",
       "1         3363  002542730X            0   \n",
       "2        11676  002542730X            6   \n",
       "3        12538  002542730X           10   \n",
       "4        13552  002542730X            0   \n",
       "...        ...         ...          ...   \n",
       "80889   234828  0345333926            8   \n",
       "80890   236283  0345333926            0   \n",
       "80891   249628  0345333926            0   \n",
       "80892   261829  0345333926            0   \n",
       "80893   264321  0345333926            8   \n",
       "\n",
       "                                              Book-Title  \n",
       "0      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "1      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "2      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "3      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "4      Politically Correct Bedtime Stories: Modern Ta...  \n",
       "...                                                  ...  \n",
       "80889                                          Ringworld  \n",
       "80890                                          Ringworld  \n",
       "80891                                          Ringworld  \n",
       "80892                                          Ringworld  \n",
       "80893                                          Ringworld  \n",
       "\n",
       "[80894 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the recommendation system, it is prefered to have the book titles rather than ISBN for easier interpretation\n",
    "\n",
    "rating = rating.merge(book, on=\"ISBN\")[['User-ID','ISBN','Book-Rating','Book-Title']] # merging with the book dataframe\n",
    "rating    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6f4bd",
   "metadata": {},
   "source": [
    "# Using surprise for data with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3ee5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a surprise object\n",
    "\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "# data_nonzero   = Dataset.load_from_df(ratings_explicit[['User-ID','ISBN','Book-Rating']], reader)\n",
    "data  = Dataset.load_from_df(rating[['User-ID','ISBN','Book-Rating']], reader)\n",
    "\n",
    "\n",
    "# Split the data into training & testing sets. Python's surprise documentation has the steps detailed out\n",
    "# https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "\n",
    "raw_ratings = data.raw_ratings\n",
    "random.shuffle(raw_ratings)                 # shuffle dataset\n",
    "\n",
    "threshold   = int(len(raw_ratings)*0.8)\n",
    "\n",
    "train_raw_ratings = raw_ratings[:threshold] # 80% of data is trainset\n",
    "test_raw_ratings  = raw_ratings[threshold:] # 20% of data is testset\n",
    "\n",
    "data.raw_ratings = train_raw_ratings        # data is now the trainset\n",
    "trainset         = data.build_full_trainset() \n",
    "testset          = data.construct_testset(test_raw_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9174eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying KNN (K-Nearest Neighbors) & SVD (Singluar Value decomposition) algorithms using default model parameters\n",
    "\n",
    "models=[KNNBasic(),KNNWithMeans(),KNNWithZScore(),KNNBaseline()] \n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    # perform 5 fold cross validation\n",
    "    # evaluation metrics: mean absolute error & root mean square error\n",
    "    CV_scores = cross_validate(model, data, measures=[\"MAE\",\"RMSE\"], cv=5, n_jobs=-1)  \n",
    "    \n",
    "    # storing the average score across the 5 fold cross validation for each model\n",
    "    result = pd.DataFrame.from_dict(CV_scores).mean(axis=0).\\\n",
    "             rename({'test_mae':'MAE', 'test_rmse': 'RMSE'})\n",
    "    results[str(model).split(\"algorithms.\")[1].split(\"object \")[0]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc411434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knns.KNNWithMeans</th>\n",
       "      <td>2.339969</td>\n",
       "      <td>3.286527</td>\n",
       "      <td>0.099924</td>\n",
       "      <td>0.433868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNBaseline</th>\n",
       "      <td>2.351632</td>\n",
       "      <td>3.300958</td>\n",
       "      <td>0.116834</td>\n",
       "      <td>0.551336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNWithZScore</th>\n",
       "      <td>2.317756</td>\n",
       "      <td>3.320688</td>\n",
       "      <td>0.136030</td>\n",
       "      <td>0.502113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNBasic</th>\n",
       "      <td>2.445319</td>\n",
       "      <td>3.511819</td>\n",
       "      <td>0.101423</td>\n",
       "      <td>0.387488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MAE      RMSE  fit_time  test_time\n",
       "knns.KNNWithMeans    2.339969  3.286527  0.099924   0.433868\n",
       "knns.KNNBaseline     2.351632  3.300958  0.116834   0.551336\n",
       "knns.KNNWithZScore   2.317756  3.320688  0.136030   0.502113\n",
       "knns.KNNBasic        2.445319  3.511819  0.101423   0.387488"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df = pd.DataFrame.from_dict(results)\n",
    "print(\"Model Performance: \\n\")\n",
    "performance_df.T.sort_values(by='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "755bf90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18651, 4)\n",
      "(62243, 4)\n"
     ]
    }
   ],
   "source": [
    "ratings_explicit=rating[rating['Book-Rating']!=0]\n",
    "ratings_implicit=rating[rating['Book-Rating']==0]\n",
    "print(ratings_explicit.shape)\n",
    "print(ratings_implicit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8085475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.3284588885019644\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.2296199800949346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNWithMeans\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNNWithMeans = GridSearchCV(KNNWithMeans, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNNWithMeans.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNNWithMeans.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNNWithMeans.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNNWithMeans.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNNWithMeans.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56e8e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.2844788326478245\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.203342423517102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNBasic\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNNBasic = GridSearchCV(KNNBasic, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNNBasic.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNNBasic.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNNBasic.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNNBasic.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNNBasic.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7002b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.301002322519768\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.2499338938617335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNWithZScore\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNN = GridSearchCV(KNNWithZScore, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNN.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNN.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNN.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNN.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNN.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6264c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Best Parameters:  {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "MAE Best Score:       2.3016933287643933\n",
      "\n",
      "RMSE Best Parameters: {'sim_options': {'name': 'pearson_baseline', 'min_support': 1, 'user_based': False}}\n",
      "RMSE Best Score:      3.1969311857393246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - KNNBaseLine\n",
    "\n",
    "param_grid = { 'sim_options' : {'name': ['msd','pearson','pearson_baseline'], \\\n",
    "                                'min_support': [1,5], \\\n",
    "                                'user_based': [False, True]}\n",
    "             }\n",
    "\n",
    "gridsearchKNN = GridSearchCV(KNNBaseline, param_grid, measures=['mae', 'rmse'], \\\n",
    "                                      cv=5, n_jobs=-1)\n",
    "                                    \n",
    "gridsearchKNN.fit(data)\n",
    "\n",
    "print(f'MAE Best Parameters:  {gridsearchKNN.best_params[\"mae\"]}')\n",
    "print(f'MAE Best Score:       {gridsearchKNN.best_score[\"mae\"]}\\n')\n",
    "\n",
    "print(f'RMSE Best Parameters: {gridsearchKNN.best_params[\"rmse\"]}')\n",
    "print(f'RMSE Best Score:      {gridsearchKNN.best_score[\"rmse\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9aed9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.1828  3.1822  3.2248  3.1825  3.1970  3.1939  0.0165  \n",
      "MAE (testset)     2.2893  2.2955  2.3159  2.2856  2.3178  2.3008  0.0135  \n",
      "Fit time          1.22    1.21    1.29    1.27    1.30    1.26    0.04    \n",
      "Test time         1.38    1.62    1.46    1.38    1.55    1.48    0.10    \n"
     ]
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "CV_score = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a166e8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.2650  3.2475  3.2522  3.2123  3.2753  3.2505  0.0214  \n",
      "MAE (testset)     2.3319  2.3298  2.3334  2.2971  2.3513  2.3287  0.0175  \n",
      "Fit time          1.38    1.27    1.29    1.31    1.26    1.30    0.04    \n",
      "Test time         1.28    1.28    1.30    1.35    1.27    1.29    0.03    \n"
     ]
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "algo = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "CV_score = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc9ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.2128  3.2361  3.2482  3.2299  3.2449  3.2344  0.0126  \n",
      "MAE (testset)     2.3442  2.3562  2.3586  2.3530  2.3448  2.3513  0.0059  \n",
      "Fit time          1.26    1.23    1.70    1.30    1.73    1.45    0.22    \n",
      "Test time         1.26    1.35    1.36    1.31    1.34    1.32    0.03    \n"
     ]
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "CV_score = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a96199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    3.2071  3.1840  3.2028  3.2508  3.2145  3.2118  0.0219  \n",
      "MAE (testset)     2.2903  2.2759  2.2801  2.3134  2.2982  2.2916  0.0134  \n",
      "Fit time          1.39    1.62    1.30    1.21    1.25    1.35    0.15    \n",
      "Test time         1.36    1.25    1.27    1.33    1.26    1.30    0.04    \n"
     ]
    }
   ],
   "source": [
    "sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "CV_score = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abcb5328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.2698\n",
      "RMSE: 3.1578\n",
      "MAE: 2.269802752286133, RMSE: 3.1577924472790557\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNBasic\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9c6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.3095\n",
      "RMSE: 3.1703\n",
      "MAE: 2.309466516844791, RMSE: 3.170283856829827\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithMeans\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db9807cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.2701\n",
      "RMSE: 3.1403\n",
      "MAE: 2.2700706051895785, RMSE: 3.1402876201004912\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNBaseline\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d2b1aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Unbiased Testing Performance:\n",
      "MAE:  2.2945\n",
      "RMSE: 3.1917\n",
      "MAE: 2.294453929096315, RMSE: 3.1916656751227\n"
     ]
    }
   ],
   "source": [
    "# Model fit & prediction - KNNWithZScore\n",
    "\n",
    "sim_options = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "final_model = KNNWithZScore(sim_options=sim_options)\n",
    "\n",
    "# Fitting the model on trainset & predicting on testset, printing test accuracy\n",
    "pred = final_model.fit(trainset).test(testset)\n",
    "\n",
    "print(f'\\nUnbiased Testing Performance:')\n",
    "print(f'MAE: {accuracy.mae(pred)}, RMSE: {accuracy.rmse(pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3057000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBasic\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "    similarity_matrix = KNNBasic(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "071b20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0380002930',\n",
       " '044661064X',\n",
       " '0553586122',\n",
       " '0446606243',\n",
       " '0671020293',\n",
       " '0060188731',\n",
       " '0345389417',\n",
       " '0515120278',\n",
       " '0345313151',\n",
       " '0515125628',\n",
       " '0440235154']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28b76663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0380002930</td>\n",
       "      <td>Watership Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>044661064X</td>\n",
       "      <td>The First Counsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0553586122</td>\n",
       "      <td>Reap the Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0446606243</td>\n",
       "      <td>The Tenth Justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0671020293</td>\n",
       "      <td>Butterfly (Orphans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0060188731</td>\n",
       "      <td>Bel Canto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0345389417</td>\n",
       "      <td>Servant of the Bones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0515120278</td>\n",
       "      <td>The Cat Who Said Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0345313151</td>\n",
       "      <td>Bearing an Hourglass (Incarnations of Immortal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0515125628</td>\n",
       "      <td>The Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0440235154</td>\n",
       "      <td>Where You Belong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title\n",
       "0   0380002930                                     Watership Down\n",
       "1   044661064X                                  The First Counsel\n",
       "2   0553586122                                      Reap the Wind\n",
       "3   0446606243                                  The Tenth Justice\n",
       "4   0671020293                                Butterfly (Orphans)\n",
       "5   0060188731                                          Bel Canto\n",
       "6   0345389417                               Servant of the Bones\n",
       "7   0515120278                            The Cat Who Said Cheese\n",
       "8   0345313151  Bearing an Hourglass (Incarnations of Immortal...\n",
       "9   0515125628                                         The Target\n",
       "10  0440235154                                   Where You Belong"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a731635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBaseline\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':5,'user_based':False}\n",
    "    similarity_matrix = KNNBaseline(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4da0df58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0380002930',\n",
       " '044661064X',\n",
       " '0446606243',\n",
       " '0671020293',\n",
       " '0345404319',\n",
       " '0440178002',\n",
       " '0345389417',\n",
       " '0312976275',\n",
       " '0515125628',\n",
       " '0440235154',\n",
       " '0439136369']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95fc1ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0380002930</td>\n",
       "      <td>Watership Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>044661064X</td>\n",
       "      <td>The First Counsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0446606243</td>\n",
       "      <td>The Tenth Justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0671020293</td>\n",
       "      <td>Butterfly (Orphans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0345404319</td>\n",
       "      <td>Taltos: Lives of the Mayfair Witches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0440178002</td>\n",
       "      <td>Shogun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0345389417</td>\n",
       "      <td>Servant of the Bones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0312976275</td>\n",
       "      <td>Hot Six : A Stephanie Plum Novel (A Stephanie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0515125628</td>\n",
       "      <td>The Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0440235154</td>\n",
       "      <td>Where You Belong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0439136369</td>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title\n",
       "0   0380002930                                     Watership Down\n",
       "1   044661064X                                  The First Counsel\n",
       "2   0446606243                                  The Tenth Justice\n",
       "3   0671020293                                Butterfly (Orphans)\n",
       "4   0345404319               Taltos: Lives of the Mayfair Witches\n",
       "5   0440178002                                             Shogun\n",
       "6   0345389417                               Servant of the Bones\n",
       "7   0312976275  Hot Six : A Stephanie Plum Novel (A Stephanie ...\n",
       "8   0515125628                                         The Target\n",
       "9   0440235154                                   Where You Belong\n",
       "10  0439136369  Harry Potter and the Prisoner of Azkaban (Book 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73c62a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNWithMeans\n",
    "\n",
    "def generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'pearson_baseline','min_support':1,'user_based':False}\n",
    "    similarity_matrix = KNNWithMeans(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a13eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0380002930',\n",
       " '044661064X',\n",
       " '0553586122',\n",
       " '0446606243',\n",
       " '0671020293',\n",
       " '0060188731',\n",
       " '0345389417',\n",
       " '0515120278',\n",
       " '0345313151',\n",
       " '0515125628',\n",
       " '0440235154']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=13552, like_recommend=40, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d3e8b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0380002930</td>\n",
       "      <td>Watership Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>044661064X</td>\n",
       "      <td>The First Counsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0553586122</td>\n",
       "      <td>Reap the Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0446606243</td>\n",
       "      <td>The Tenth Justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0671020293</td>\n",
       "      <td>Butterfly (Orphans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0060188731</td>\n",
       "      <td>Bel Canto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0345389417</td>\n",
       "      <td>Servant of the Bones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0515120278</td>\n",
       "      <td>The Cat Who Said Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0345313151</td>\n",
       "      <td>Bearing an Hourglass (Incarnations of Immortal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0515125628</td>\n",
       "      <td>The Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0440235154</td>\n",
       "      <td>Where You Belong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title\n",
       "0   0380002930                                     Watership Down\n",
       "1   044661064X                                  The First Counsel\n",
       "2   0553586122                                      Reap the Wind\n",
       "3   0446606243                                  The Tenth Justice\n",
       "4   0671020293                                Butterfly (Orphans)\n",
       "5   0060188731                                          Bel Canto\n",
       "6   0345389417                               Servant of the Bones\n",
       "7   0515120278                            The Cat Who Said Cheese\n",
       "8   0345313151  Bearing an Hourglass (Incarnations of Immortal...\n",
       "9   0515125628                                         The Target\n",
       "10  0440235154                                   Where You Belong"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = pd.DataFrame(recommendationsKNN,columns = ['ISBN'])\n",
    "red_ = red.merge(book, on=\"ISBN\")[['ISBN','Book-Title']]\n",
    "red_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359537b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
